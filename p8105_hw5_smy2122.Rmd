---
title: "Homework 5"
author: "Sarah Younes"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

As always, I will begin by loading the packages I will need for this assignment: tidyverse. Then, I will `set.seed` so that I get the same values in Problem 3 when I generate data sets and enhance reproducibility. Additionally, I will set my theme and legend position for my plots.

```{r load packages & set seed & set theme, message = FALSE}
library(tidyverse)
set.seed(1)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
```

## Problem 1

First, I will import the data.

```{r raw data}
homicide_data =
  read.csv("./data/homicide-data.csv")
```

Next, I will clean the data.

```{r cleaning data}
homicide_data =
  homicide_data |>
  janitor::clean_names() |>
  mutate(
    victim_last = str_to_title(victim_last),
    victim_first = str_to_title(victim_first)) |>
  mutate(city_state = paste(city, state, sep = ", "))
```

Now, I will summarize within cities to obtain the total number of homicides and the total number of unsolved homicides, and I will show both of these values for each city.

```{r city summaries}
total_homicides =
  homicide_data |>
  group_by(city) |>
  summarize(
    total_homicides = n())

unresolved_homicides =
  homicide_data |>
  filter(disposition == "Closed without arrest" | disposition == "Open/No arrest") |>
  group_by(city) |>
  summarize(
    unresolved_homicides = n())

city_summaries =
  full_join(total_homicides, unresolved_homicides, by = "city") |>
  print(n = Inf)
```

## Problem 2

First, I will start with a data frame containing all file names.

```{r file names}
csv_files =
  list.files(path = "./data/problem_2", pattern = "\\.csv$", full.names = TRUE)

csv_files_df =
  csv_files |>
  tibble()
```

First, I will create a data frame containing all file names via `list.files` and paths. Then, I will use `purrr::map` to import each csv file into the data frame, and all their data is saved as a new `data` variable in the data frame.

```{r importing data, message = FALSE, warning = FALSE}
df =
  tibble(
    files = list.files("./data/problem_2/", pattern = "\\.csv$"),
    path = str_c("./data/problem_2/", files)) |>
  mutate(
    data = map(path, read_csv))

df
```

Next, I will clean the data to unnest all the weekly data from the `data` variable, create ID and study arm variables,tidy the week variable, set `week` as a numeric value, and select the variables I need.

```{r tidying}
tidy_df =
  df |>
  unnest(cols = c(data)) |>
  mutate(
    id = str_extract(files, "\\d+"),
    arm = str_extract(files, "con|exp")) |>
  pivot_longer(
    week_1:week_8,
    names_to = "week",
    names_prefix = "week_",
    values_to = "value") |>
  mutate(
    week = as.numeric(week)) |>
  select(id, arm, week, value)

tidy_df
```

Now, I will make a spaghetti plot showing the observations for each subject over time by study arm/treatment group (experimental vs. control). Most study participants started around the same values. The control group remained mostly the same but trended slightly downward over the 8-week period whereas the experimental group saw larger improvements, which indicates there was likely not a placebo effect among the control group since between-group differences were noticeable. Some participants in the control group showed large fluctuations in observation value over the 8-week period.

```{r spaghetti plot}
tidy_df |>
  ggplot(aes(x = week, y = value, color = id)) +
  geom_line() +
  facet_grid(. ~ arm, labeller = labeller(arm = c(con = "Control group", exp = "Experimental group"))) +
  labs(
    x = "Week",
    y = "Observation value",
    title = "Observations over time by subject ID and treatment group",
    color = "Subject ID")
```

## Problem 3

First, I will create a function that runs a one-sample t-test with n = 30, mu = 0,  sigma = 5, and an alpha level of 0.05.

```{r t-test simulation}
t_test_simulations = function(n = 30, mu = mu, sd = 5) {

    data =
      tibble(
        x = rnorm(n = 30, mean = mu, sd = 5))
    
    t_test =
      t.test(pull(data, x), mean = 0, conf.level = 1 - 0.05) |>
      broom::tidy()
   
  return(
    tibble(
      mu = mu,
      mu_hat = pull(t_test, estimate),
      p_value = pull(t_test, p.value)))
    
}

## test function

t_test_simulations(mu = 0)
```

Next, I will run the function 5000 times with mu = 0.

```{r}
output = vector("list", 5000)

for (i in 1:5000) {
  
  output[[i]] = t_test_simulations(n = 30, mu = 0, sd = 5)
  
}

sim_results_mu_0 = bind_rows(output)

sim_results_mu_0
```

Now, I will run the function 5000 times with mu = 0:6.

```{r}
sim_results_all_mu =
  expand_grid(
    mu_values = 0:6,
    iter = 1:5000) |>
  mutate(
    estimate_df = pmap(list(n = 30, mu = mu_values), t_test_simulations)) |>
  unnest(estimate_df)
```

Next, I will make a plot showing the proportion of the number of times the null was rejected on the y-axis and the true value of mu on the x-axis. As the mu value increases, the null is more likely to be rejected, and this effect plateaus when mu = 4. Thus, as the effect size increase, power increases.

```{r first plot}
## 1 indicates rejecting the null hypothesis, 0 indicates failing to reject the null hypothesis

sim_results_all_mu |>
  mutate(
    null_rejected = case_when(
      p_value < 0.05 ~ 1,
      p_value >= 0.05 ~ 0)) |>
  group_by(mu) |>
  summarize(
    proportion = sum(null_rejected)/n()) |>
  ggplot(aes(x = mu, y = proportion)) +
  geom_point() +
  geom_line() +
  labs(
    title = "Proportion of the number of times the null was rejected for each true mu value",
    x = "Proportion of number of times the null was rejected",
    y = "True mu value")
```

Next, I will make two plots. The first will show the average estimate of mu-hat on the y-axis and the true value of mu on the x-axis for all samples, and the second will show the average estimate of mu-hat only in samples for which the null was rejected on the y-axis and the true value of mu on the x-axis.

```{r}
all_samples =
  sim_results_all_mu |>
  group_by(mu) |>
  summarize(
    mean_mu_hat = mean(mu_hat)) |>
  ggplot(aes(y = mean_mu_hat, x = mu)) +
  geom_point() +
  geom_line()

all_samples
```

```{r}
rejected_samples =
  sim_results_all_mu |>
  filter(p_value < 0.05) |>
  group_by(mu) |>
  summarize(
    mean_mu_hat = mean(mu_hat)) |>
  ggplot(aes(y = mean_mu_hat, x = mu)) +
  geom_point() +
  geom_line()

rejected_samples
```

```{r}
sim_results_all_mu |>
  group_by(mu) |>
  summarize(mean_mu_hat = mean(mu_hat)) |>
  ungroup() |>
  filter(p_value < 0.05) |>
  group_by(mu) |>
  summarize(mean_mu_hat = mean(mu_hat))
```